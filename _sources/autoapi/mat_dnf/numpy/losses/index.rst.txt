mat_dnf.numpy.losses
====================

.. py:module:: mat_dnf.numpy.losses

.. autoapi-nested-parse::

   Losses and error metrics.



Functions
---------

.. autoapisummary::

   mat_dnf.numpy.losses.classification_error
   mat_dnf.numpy.losses.approximation_error
   mat_dnf.numpy.losses.logi_conseq
   mat_dnf.numpy.losses.logi_equiv
   mat_dnf.numpy.losses.acc_classi
   mat_dnf.numpy.losses.acc_dnf


Module Contents
---------------

.. py:function:: classification_error(i_out, v_k, split_v_k = 20)

   Compute minimum classification error  Er_k=|I2-(V_k>=V_k_th)|.

   :param i_out: 0-1 row vector representing target truth values corresponding to i_in.
   :param v_k: Number of satisfied disjuncts.
   :param split_v_k: Number of threshold bins for disjunction V_k = D_k*M.

   :returns: Minimum error by predicted I2_k(= V_k >= V_k_th).
             v_k_th: Thresholded v_k value
   :rtype: er_k


.. py:function:: approximation_error(c, d_k, d_i_in, i_out, split_c = 10, split_d_k = 10)

   Compute minimum approximation error Er_k_th by {D_k_th, C_th}.

   :param c: C-part of learned DNF (continuous space).   # (h, 2n) where n=#variables and h is the maximum number of conjunctions in a DNF.
   :param d_k: D-part of learned DNF (continuous space). # (h,)
   :param d_i_in: Dualized matrix of l data points in n variables to be classified.
   :param i_out: 0-1 row vector representing target truth values corresponding to i_in.
   :param split_c: Number of threshold bins for h conjunctions C.
   :param split_d_k: Number of threshold bins for disjunction D_k.

   :returns: The minimum approximation error.
             c_th: (h x 2n) 0-1 Mat for conjunction.
             d_k_th: (1 x h) 0-1 Mat for disjunction.
   :rtype: er_k_th


.. py:function:: logi_conseq(dnf, i_out, i_in)

   Logical consequence. |= phi_0 => phi
   s.t.
     phi:= dnf
     phi_0:= (i_in, i_out)

   If i_in_true |= dnf, conseq = 1.
   O.w. conseq = 0 and couner_example = I_in_counter

   :param dnf: #clause x (2x#variables)
   :param i_out: 0-1 row vector (L,) representing target truth values corresponding to i_in with L: interpretation.
   :param i_in: 0-1 matrix (N,L) with N: #variables

   :returns: logical equivalence
             profile: #variable x non-equivalent interpretations
   :rtype: bool


.. py:function:: logi_equiv(dnf, i_out, i_in)

   Logical equivalence. |= phi_0 <=> phi
   s.t.
     phi:= dnf
     phi_0:= (i_in, i_out)

   :param dnf: #clause x (2x#variables)
   :param i_out: 0-1 row vector (L,) representing target truth values corresponding to i_in with L: interpretation.
   :param i_in: 0-1 matrix (N,L) with N: #variables

   :returns: logical equivalence
             profile: #variable x non-equivalent interpretations
   :rtype: bool


.. py:function:: acc_classi(d_k, v_k_th, i1, i2_k, l2, c)

   accuracy metric predicted by soft DNF for the learned DNF.
   1/L \sum 1_{y_pred=i2_k}
   where y_pred is computed by continual weighted clauses

   :param d_k: D-part of learned DNF (continuous space). # (h,)
   :param v_k_th: threshold scalar value
   :param i1: i_in inputs
   :param i2_k: i_out outputs
   :param l2: =L(#interpretation)
   :param c: C-part of learned DNF (continuous space).   # (h, 2n) where n=#variables and h is the maximum number of conjunctions in a DNF.


.. py:function:: acc_dnf(dnf, i1, i2_k, l2)

   accuracy metric predicted by the learned DNF.
   1/L \sum 1_{y_pred=i2_k}
   where y_pred is computed by discretized clauses

   :param dnf: #clause x (2x#variables)
   :param i1: (i_in) 0-1 matrix (N,L) with N: #variables
   :param i2_k: (i_out) 0-1 row vector (L,) representing target truth values corresponding to i_in with L: #interpretation.
   :param l2: =L(#interpretation)


